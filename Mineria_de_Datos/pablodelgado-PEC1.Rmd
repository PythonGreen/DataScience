---
title: 'Minería de datos: PEC1'
author: "Autor: Nombre estudiante"
date: "Octubre 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******
## Presentación
Esta prueba de evaluación continuada cubre el módulo 1,2 y 8 del programa de la asignatura.  

## Competencias
Las competencias que se trabajan en esta prueba son:

* Uso y aplicación de las TIC en el ámbito académico y profesional
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes, así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.
* Capacidad de utilizar un lenguaje de programación.  
* Capacidad para desarrollar en una herramienta IDE.  
* Capacidad de plantear un proyecto de minería de datos.  

## Objetivos
* Asimilar correctamente el módulo 1 y 2.
*	Qué es y qué no es MD.
*	Ciclo de vida de los proyectos de MD.
*	Diferentes tipologías de MD.
* Conocer las técnicas propias de una fase de preparación de datos y objetivos a alcanzar.  

## Descripción de la PEC a realizar
La prueba está estructurada en 1 ejercicio teórico/práctico y 1 ejercicio práctico que pide que se desarrolle la fase de preparación en un juego de datos.  
Deben responderse todos los ejercicios para poder superar la PEC.  

## Recursos
Para realizar esta práctica recomendamos la lectura de los siguientes documentos:  

* Módulo 1, 2 y 8 del material didáctico.  
* RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  
* R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada apartado del ejercicio práctico qué se ha hecho y cómo se ha hecho.  

## Formato y fecha de entrega
El formato de entrega es: usernameestudiant-PECn.html y rmd  
Fecha de Entrega: 28/10/2020  
Se debe entregar la PEC en el buzón de entregas del aula  


## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en qué se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia  no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado  
******
Como ejemplo, trabajaremos con el conjunto de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".   

De momento dejaremos para las siguientes prácticas el estudio de algoritmos predictivos y nos centraremos por ahora en el estudio de las variables de una muestra de datos, es decir, haremos un trabajo descriptivo del mismo. 

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de características o variables y la preparación del los  datos para posteriormente ser consumido por un algoritmo.

Las técnicas que trabajaremos son las siguientes:  

1. Normalización  
2. Discretización  
3. Gestión de valores nulos  
4. Estudio de correlaciones  
5. Reducción de la dimensionalidad
6. Análisis visual del conjunto de datos  

******
# Ejemplo de estudio visual con el juego de datos Titanic
******

## Procesos de limpieza del conjunto de datos

Primer contacto con el conjunto de datos, visualizamos su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)


# Cargamos el fichero de datos
totalData <- read.csv('titanic.csv',stringsAsFactors = FALSE)
filas=dim(totalData)[1]

# Verificamos la estructura del conjunto de datos
str(totalData)
```
Descripción de las variables contenidas en el fichero:

name
    a string with the name of the passenger.
    
gender
    a factor with levels male and female.
    
age
    a numeric value with the persons age on the day of the sinking. The age of babies (under 12 months) is given as a fraction of one year (1/month).
    
class
    a factor specifying the class for passengers or the type of service aboard for crew members.
    
embarked
    a factor with the persons place of of embarkment.
    
country
    a factor with the persons home country.
    
ticketno
    a numeric value specifying the persons ticket number (NA for crew members).
    
fare
    a numeric value with the ticket price (NA for crew members, musicians and employees of the shipyard company).
    
sibsp
    an ordered factor specifying the number if siblings/spouses aboard; adopted from Vanderbild data set.
    
parch
    an ordered factor specifying the number of parents/children aboard; adopted from Vanderbild data set.
    
survived
    a factor with two levels (no and yes) specifying whether the person has survived the sinking.
    

Mostramos estadísticas bàsicas y después trabajamos los atributos con valores vacíos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Estadísticas básicas
summary(totalData)

# Estadísticas de valores vacíos
colSums(is.na(totalData))
colSums(totalData=="")

# Tomamos valor "Desconocido" para los valores vacíos de la variable "country"
totalData$Embarked[totalData$country==""]="Desconocido"

# Tomamos la media para valores vacíos de la variable "Age"
totalData$Age[is.na(totalData$age)] <- mean(totalData$age,na.rm=T)
```

Discretizamos cuando tiene sentido y en función de las capacidades de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Añadimos una variable nueva a los datos. Este valor es la edad discretizada con un método simple de intervalos de igual amplitud.
# Vemos cómo se distribuyen los valore
summary(totalData[,"age"])
# Discretizamos
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
# Observamos los datos discretizados.
head(totalData)
# Vemos como se agrupan los datos.
plot(totalData$segmento_edad)
```


## Procesos de análisis del conjunto de datos

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "survival":
ggplot(data=totalData[1:filas,],aes(x=gender,fill=survived))+geom_bar()

# Otro punto de vista. Survival como función de Embarked:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

En la primera gráfica podemos observar fácilmente la cantidad de mujeres que viajaban respecto hombres y observar los que no sobrevivieron. Numéricamente el número de hombres y mujeres supervivientes es similar.

En la segunda gráfica de forma porcentual observamos los puertos de embarque y los porcentajes de supervivencia en función del puerto. Se podría trabajar el puerto C (Cherburgo) para ver de explicar la diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o niños... O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 56.45%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$embarked, totalData[1:filas,]$survived )
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se podría hacer un gráfico similar trabajando solo la clase. Habría que unificar toda la tripulación a una única categoría.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```



******
# Ejercicios
******

## Ejercicio 1: 

Estudia los tres casos siguientes y contesta, de forma razonada la pregunta que se realiza:

1. Disponemos de un conjunto de variables referentes a vehículos, tales como la marca, modelo, año de matriculación, etc. También se dispone del precio al que se vendieron. Al poner a la venta a un nuevo vehículo, se dispone de las variables que lo describen, pero se desconoce el precio. ¿Qué tipo de algoritmo se debería aplicar para predecir de forma automática el precio?

2. En un almacén de naranjas se tiene una máquina, que de forma automática obtiene un conjunto de variables de cada naranja, como su tamaño, acidez, grado maduración, etc. Si se desea estudiar las naranjas por tipos, según las variables obtenidas, ¿qué tipo de algoritmo es el más adecuado?

3. Un servicio de música por internet dispone de los historiales de audición de sus clientes: Qué canciones y qué grupos eligen los clientes a lo largo del tiempo de sus escuchas. La empresa desea crear un sistema  que proponga la siguiente canción y grupo en función de la canción que se ha escuchado antes. ¿Qué tipo de algoritmo es el más adecuado?

### Respuesta 1:

> Dado que es un dominio conocido, como lo es la venta de automoviles y de que contamos con toda la informacion (atributos) correspondiente a cada uno de ellos, ademas del historial de ventas, y siendo que, lo que se intenta aqui es predecir cual sera el valor de venta actual, creo que el mejor algoritmo a aplicar es un modelo **predictivo** clasico como lo es la **regresion lineal**, ya que permite la prediccion de valores numericos (no concretos como un SI o un NO, 0 o 1, etc..) a partir una o mas variables, en este caso los distintos atributos o variables que describen a los automoviles y sus precios de venta anteriores.
Tal como se describe en distintos sitios web, como ser en [wikipedia: Regresion Lineal](https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal) o hasta [KDNuggets: Linear Regression Model](https://www.kdnuggets.com/2020/10/guide-linear-regression-models.html), en este caso el precio de venta a predecir seria la variable dependiente (target), mientras que los atributos de los coches y precios de ventas historicos sus variables independientes (inputs). Conformando asi una regresion lineal multiple que permite explorar y cuantificar la relacion entre las variables independientes y la dependiente.

### Respuesta 2:
> **Clustering**. Ya que necesito agrupar las naranjas por sus caracteristicas sin tener informacion previa de como agruparlas segun algun criterio predefinido. Si hubiesemos querido usar clasificacion, deberiamos tener alguna informacion previa acerca de como agruparlas para luego analizar cada grupo y entender mejor que las diferencia, que caracteriza cada grupo, etc... Pero como no es el caso, la mejor alternativa son los modelos de agregacion. Como ejemplo podemos tomar lo explicado en este post acerca de lo que es clustering y algunos ejemplos de tecnicas existentes: 
[comparing clustering techniques concise technical overview](https://www.kdnuggets.com/2016/09/comparing-clustering-techniques-concise-technical-overview.html)

### Respuesta 3:
> Este ultimo caso, tambien es una tarea de **prediccion** de la proxima accion del usuario, en particular la seleccion de la proxima cancion. Para ello lo mejor sera usar algun **sistema de recomendacion**. Tal como se describe a lo largo cientos de sitios web tenemos varias alternativas de sistemas de recomendacion, pero si nos enfocamos por ejemplo en el siguiente [post](https://www.kdnuggets.com/2019/09/machine-learning-recommender-systems.html) de KDNuggets el algoritmo que mejor aplica a este caso es un "**Collaborative Filtering**", ya que con la informacion que contamos son las canciones que cada usuario ha escuchado historicamente y por ende tambien que canciones o bandas en comun tiene cada usuario, y no un "**Content-based Systems**" ya que no contamos por ejemplo con un ranking de popularidad de canciones calificadas por el usuario, ni ningun otro dato propio del usuario o de la cancion en si. O sea no tenemos datos propios del usuario ni de la cancion o banda. Solamente lo que cada usuario escuchó. Por lo tanto si nos basamos solo en esto: las canciones o bandas que mas han escuchado usuarios similares, seguramente tambien le gustaran a un nuevo usuario que hasta ahora ha escuchado canciones similares a los que tiene en comun.


## Ejercicio 2:  
A partir del conjunto de datos disponible en el siguiente enlace http://archive.ics.uci.edu/ml/datasets/Adult , realiza un estudio tomando como propuesta inicial al que se ha realizado con el conjunto de datos "Titanic". Amplia la propuesta generando nuevos indicadores o solucionando otros problemas expuestos en el módulo 2. Explica el proceso que has seguido, qué conocimiento obtienes de los datos, qué objetivo te has fijado y detalla los pasos, técnicas usadas y los problemas resueltos.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de algún repositorio open data siempre que sea similar en diversidad de tipos de variables al propuesto. 

### Respuesta 2:
#### Procesos de limpieza del conjunto de datos


```{r echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(scales)

# Cargamos el juego de datos
datosAdult <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',stringsAsFactors = FALSE, header = FALSE)

# Asignamos nombres a las columnas a partir de lo informado en http://archive.ics.uci.edu/ml/datasets/Adult
names(datosAdult) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hour-per-week","native-country","income")

# Verificamos la estructura y contenido del conjunto de datos
str(datosAdult)
```
Hasta aqui los valores que toman cada variable del dataset parecen ser los descriptos en la seccion "Attribute Information" de **http://archive.ics.uci.edu/ml/datasets/Adult**

Ahondemos mas en el contenido del dataset y hagamos un muestreo de 10 filas del dataset y luego estadisticas basicas:

```{r echo=TRUE, message=FALSE, warning=FALSE}
#  Previsualicemos 30 registros del dataset para entender mejor el contenido
head(datosAdult,30)
```

Ahora veamos como dijimos estadisticas basicas del dataset
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadisticas Basicas
summary(datosAdult)
```

Y finalmente observemos todos los posibles valores de cada variable para comprender totalmente el contenido de cada variable del fichero, como tambien la existencia de valores nulos, missings o caracteres extraños.
```{r echo=TRUE, message=FALSE, warning=FALSE}

# Creamos barplots por cada variable 
barplot(table(datosAdult$age))
qplot(datosAdult$age)
barplot(table(datosAdult$workclass))
barplot(table(datosAdult$education))
barplot(table(datosAdult$`education-num`))
barplot(table(datosAdult$`marital-status`))
barplot(table(datosAdult$occupation))
barplot(table(datosAdult$relationship))
barplot(table(datosAdult$race))
barplot(table(datosAdult$sex))
barplot(table(datosAdult$`capital-gain`))
barplot(table(datosAdult$`capital-loss`))
barplot(table(datosAdult$`hour-per-week`))
barplot(table(datosAdult$`native-country`))
barplot(table(datosAdult$income))

# Estadísticas de valores vacíos
colSums(is.na(datosAdult))

# y ahora los missing
colSums(datosAdult=="")

```

Como vimos arriba no hay missings values ni nulos, pero algunas variables tiene un '?' en lugar de un valor real.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Obtenemos estadisticas de ese caracter
colSums(datosAdult=="?")

# con colSums, seguimos sin ver ese signo de pregutna, tendra espacios?
# probemos cada variable los valores distintos para tener mas pistas:
unique(datosAdult$workclass)
unique(datosAdult$occupation)
unique(datosAdult$`native-country`)

## como vimos arriba todos los valores incluso los que tienen valores correctos
## tiene espacios por delante o incluso por detras, esto puede verse
## incluso usando la funcion factor
levels(factor(datosAdult$workclass)) 

## una opcion para salvar esta situacion es aplicar trimws a los campos de texto, por ejemplo:
sum(trimws(datosAdult$workclass)=="?")

## entonces ahora si sacaramos estadisticas,  pero agregando manualmente el espacios, comprobaremos esta situacion
colSums(datosAdult==" ?")
```


Existes variables missing o nulas? que podemos haces para solucionarlo?

Dado el punto inmediato anterior donde en campos de texto se encontraron espacios de mas, realicemos algunas transformaciones para mejorar los datos para posteriores analisis. En este caso convertiremos el "?" en "Not Informed", quitando los espacios ademas de todos los campos de texto

```{r echo=TRUE, message=FALSE, warning=FALSE}
# primero, quitamos todos los espacios de los campos de texto
datosAdult$workclass <- trimws(datosAdult$workclass)
datosAdult$occupation <- trimws(datosAdult$occupation)
datosAdult$`native-country` <- trimws(datosAdult$`native-country`)
datosAdult$education <- trimws(datosAdult$education)
datosAdult$`marital-status` <- trimws(datosAdult$`marital-status`)
datosAdult$relationship <- trimws(datosAdult$relationship)
datosAdult$race <- trimws(datosAdult$race)

# y lo volvemos a chequear luego del cambio, al menos para las variables que poseia el signo de interrogacion, vemos que sigue estando, pero ahora tanto el signo como el resto de los campos sin espacios
unique(datosAdult$workclass)
unique(datosAdult$occupation)
unique(datosAdult$`native-country`)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# volvemos a chequear los signos
colSums(datosAdult=="?")

# Ahora, reemplazamos el "?" por "Unknown"
datosAdult$workclass[datosAdult$workclass=="?"]="Unknown"
datosAdult$occupation[datosAdult$occupation=="?"]="Unknown"
datosAdult$`native-country`[datosAdult$`native-country`=="?"]="Unknown"

# volvemos a chequear los signos
colSums(datosAdult=="?")
colSums(datosAdult=="Unknown")
```

Transformemos algunos atributos para aprovechamiento posterior

```{r echo=TRUE, message=FALSE, warning=FALSE}
## Intentaremos reagrupar algunos atributos, porque quizas tenga sentido para posteriores analisis, como por ej workclass y occupation.

## Ya que si lo vimos graficamente antes, si hacemos un count de cada valor vemos que estan distribuidos en clases que puede ser reagrupadas y tener grupos de cada clase
table(datosAdult$workclass)

## Esto podria quedar asi:
# Goverment: Federal-gov    Local-gov State-gov
# NoPay/Others: Never-worked  Without-pay Unknown 
# Private
# Self-Employed: Self-emp-inc  Self-emp-not-inc

# Lo hago de esta manera, si existe alguna forma mas perfomante en R, bievenida la sugerencia :)

datosAdult$workclass[datosAdult$workclass %in% c('Federal-gov','Local-gov','State-gov')]="Goverment"

datosAdult$workclass[datosAdult$workclass%in%c('Never-worked', 'Without-pay','Unknown','')]="NoPay/Others"

datosAdult$workclass[datosAdult$workclass%in%c('Self-emp-inc','Self-emp-not-inc')]="Self-Employed"

table(datosAdult$workclass)


## Lo mismo sucede con ocupacion, me parece que podria agruparse por tipo de empleo
table(datosAdult$occupation)

## Esto podria quedar asi:
# Manual_Works: Craft-repair Farming-fishing Handlers-cleaners  Transport-moving
# Admin/Proffesional: Adm-clerical Exec-managerial Machine-op-inspct Prof-specialty   
# Sales: Sales
# Services: Priv-house-serv Protective-serv Other-service Tech-support
# Others: Unknown  Armed-Forces

datosAdult$occupation[datosAdult$occupation %in% c('Craft-repair','Farming-fishing','Handlers-cleaners', 'Transport-moving')]="Manual_Works"

datosAdult$occupation[datosAdult$occupation %in% c('Adm-clerical','Exec-managerial','Machine-op-inspct','Prof-specialty','')]="Admin/Proffesional"

datosAdult$occupation[datosAdult$occupation %in% c('Priv-house-serv','Protective-serv','Other-service','Tech-support')]="Services"

datosAdult$occupation[datosAdult$occupation %in% c('Unknown', 'Armed-Forces')]="Others"

table(datosAdult$occupation)
```




Discretizemos algunas variables

```{r echo=TRUE, message=FALSE, warning=FALSE}
## Como se pudo ver en las estadisticas e historgramas anteriormenete, tnto CapitalGain como CapitalLoss, tiene muchisimos valores en 0. Asi que para mejor analisis, solo para validar y no descartarlo, lo discretizaremos en valores binarios.
datosAdult$capital_gain_flag<-ifelse(datosAdult$`capital-gain`>0,1,0)
datosAdult$capital_loss_flag<-ifelse(datosAdult$`capital-loss`>0,1,0)

# sin embargo viendo esto, parecen no aportar mucho, ya que esta todo mayormente en 0
table(datosAdult$capital_gain_flag)
table(datosAdult$capital_loss_flag)


## Para native-country haremos algo similar, debido que casi todos lo valores corresponden a USA. Separaremos en USA y Resto del Mundo, para validar si encontramos algun patron por esta variable visualmente luego
table(datosAdult$`native-country`)
datosAdult$country_classif<-ifelse(datosAdult$`native-country`=='United-States','United-States','Rest-of-the-World')

# sin embargo viendo esto, parecen no apotar mucho
table(datosAdult$country_classif)
qplot(datosAdult$country_classif)

# Parece aportar poco esta distribucion

## Ahora discretizamos age, por los clasico rangos de edades:
## 0-17 / 18-25 / 25-40 / 40-64 / +67
datosAdult["grouped_age"] <- cut(datosAdult$age, breaks = c(0,18,25,40,67,100), labels = c("0-17", "18-25", "25-40", "40-64","67-100"))

# tabularmente
table(datosAdult$grouped_age)

# graficamente:
plot(datosAdult$grouped_age)

# Tambien se podria discretiar las horas trabajadas, para los que trabajan las clasicas 40hs semanales, vs los que trabajan menos o mas de esa cantidad de horas
table(datosAdult$`hour-per-week`)

datosAdult["hours_per_week_group"] <- cut(datosAdult$`hour-per-week`, breaks = c(0,39,40,100), labels = c("-40", "40", "+40"))

# tabularmente
table(datosAdult$hours_per_week_group)
# graficamente:
plot(datosAdult$hours_per_week_group)


# Por ultimo discretizamos el nivel de educacion
datosAdult$education[datosAdult$education %in% c('10th','11th','12th','1st-4th','5th-6th','7th-8th','9th','Preschool', 'HS-grad', 'Some-college')]="PreBachelors"
datosAdult$education[datosAdult$education %in% c('Assoc-acdm','Assoc-voc')]="Associate"

```



#### Proceso de analisis visual de variables y relaciones

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Comencemos a analizar el income por las distintas variables

#------------------------------------------------------------------------------
# Como es la distribucion del ingreso segun el rango de edad, en cantidades y como frecuencia/porcentaje
ggplot(data=datosAdult[1:filas,],aes(x=grouped_age,fill=income))+geom_bar()

ggplot(data=datosAdult[1:filas,],aes(x=grouped_age,fill=income))+geom_bar(position="fill")+ylab("Frecuencia")


# Aca claramente podemos determinar que la mayor cantidad de ingresos se da en las personas mayores de 25 y menores a 65 anos, justamente la edad promedio donde se termina la universidad y la edad de jubilacion de las personas. Podemos decir que hay una relacion entre la edad laboral y el ingreso anual.
#------------------------------------------------------------------------------
# Veamos el income por sexo
ggplot(data=datosAdult[1:filas,],aes(x=sex,fill=income))+geom_bar(position="fill")+ylab("Frecuencia")
## El grafico indica que los hombres ganan mas que las mujeres

  
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, combinemos algunas variables para sacar alguna otra conclusion
ggplot(data = datosAdult[1:filas,],aes(x=grouped_age,fill=income))+geom_bar(position="fill")+facet_wrap(~sex)

# Aqui vemos que sean hombres o mujeres, el rango etario de mayor ingreso sigue siendo el de 25 a 65 años y se mantiene el hecho de que los hombres ganen mas. Aunque al parecer luego de la edad de jubilacion hay mas mujeres obteniendo mejores jubilaciones. Evaluemos ese grupo:

#Sabemos por esto que son mas hombres que mujeres
table(datosAdult$sex[datosAdult$grouped_age=='67-100'])
# Asi todo siendo menor cantidad, podemos confirmar, que las mujeres luego de su jubilacion tiene mayores ingresos que los hombres

#------------------------------------------------------------------------------
```

Analicemos ahora temas como cantidad de horas trabajas, workclass, education y ocupacion, siguiendo el estado civil y las variables que teniamos pendiente validar como capital gain y loss. Para terminar analizando las razas y paises.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Primero vamos por workclass, cantidad de horas trabajadas, education y ocupacion
#----------------WORKCLASS-----------------------------------------------------
ggplot(data=datosAdult[1:filas,],aes(x=workclass,fill=income))+geom_bar()
# Como vemos el sector privado es es donde se generan mayor ingreso, pero a la vez es donde mayor cantidad de personas tenemos con ingresos menores a 50k. 
# Al verlo en porcentajes es mucho mas claro:
ggplot(data=datosAdult[1:filas,],aes(x=workclass,fill=income))+geom_bar(position="fill")+scale_y_continuous(labels=scales::percent)
# Por lo que si bien la mayor masa salarial es generada en ese sector, eso no garantiza que pertenecer al sector privado te genere mas ingresos. Casi todo lo contrario, de hecho trabajando para el gobierno, tendrias mas posibilidad de obtener mas ingresos, incluso mas aun trabajando por cuenta propia. 
#---------------HORAS POR SEMANA -----------------------------------------------
# Veamos que pasa con las horas trabajadas:
ggplot(data=datosAdult[1:filas,],aes(x=hours_per_week_group,fill=income))+geom_bar(position="fill")+scale_y_continuous(labels=scales::percent)
# Lamentablemente para todos, esto representa que cuanto mas horas dediquemos por semana mayor sera el ingreso, eso de trabajar poco y ganar mas claramente el grafico muestra que es para pocos.


#----------------EDUCACION------------------------------------------------------
# Rapidamente vemos que cuanto mas años se dediquen a educacion en general mayores ingresos se tendran
ggplot(data=datosAdult[1:filas,],aes(x=`education-num`,fill=income))+geom_bar(position="fill")

# Mientra que si lo vemos por los estudio obtenidos
ggplot(data=datosAdult[1:filas,],aes(x=education,fill=income))+geom_bar(position="fill",width = 0.2) 
# Evidentemente hay una relaion entre el nivel de estudios y el nivel de ingreso, y obviamente el nivel de estudios esta atado a los años dedicados a ellos. Es por eso que a mas años, mayor nivel educativo y por consecuencia en general mayores ingresos.


#----------------OCUPACION------------------------------------------------------
# Como podemos imaginarnos los profesionales, personas en rangos de administracion y areas de ventas pueden obtener grandes ingresos. Mientras que los trabajos manuales y los servicios son los que menos ingresos generan
ggplot(data=datosAdult[1:filas,],aes(x=occupation,fill=income))+geom_bar(position="fill")

# Por ultimo estado civil y las variables que teniamos pendiente validar como capital gain y loss
#----------------ESTADO CIVIL-----------------------------------------------------
# Como vemos marcadamente aqui, el estado civil si que importa a la hora de obtener mayores ingresos. Las personas casadas son las que en porcentaje mayores ingresos tienen respecto a las que no lo estan. Una razon se deba tal vez a la estabilidad emocional y economica que pueda generar a largo plazo un matrimonio establecido. 
ggplot(data=datosAdult[1:filas,],aes(x=`marital-status`,fill=income))+geom_bar(position="fill")+theme(axis.text=element_text(size=8,angle=45))

#Nota: He girado 45 grados y achicado el texto de las variables para que sea mas claro el grafico. He buscado en Stackerflow como girar en este caso los texto del eje x. Podria hacer lo mismo para todos los ejes o por eje inviualmente como he hecho aqui.

# Incluso es mas notorio si lo contrastamos con alguna otra variable, como es la ocupacion, donde vimos anteriormente que invididualmente se destacaban mas los puestos de administracion/profesionales o ventas, pero si lo contrastamos contra el estado civil vemos que sea la profesion que sea te ira mejor si estas casado.
ggplot(data=datosAdult[1:filas,],aes(x=occupation,fill=income))+geom_bar(position="fill")+theme(axis.text.x=element_text(size=8,angle=45))+facet_wrap(~`marital-status`)
   
# Esto confirma un poco mas lo dicho antes, el hecho de estar casado implica mayor ingreso, y analizar si eres esposo o esposa no cambia la distribucion, lo que importa es el estado civil, es decir estar casado. Es un factor determinante.
ggplot(data=datosAdult[1:filas,],aes(x=relationship,fill=income))+geom_bar(position="fill")+theme(axis.text=element_text(size=8,angle=45))

#----------------CAPITALs-----------------------------------------------------
# Como dijimos antes, la hipotesis es que las variabels de capital no aportarian nada paara el analisis, pero hagamos un analisis real y comprobemoslo para entender si deberan ser excluidos para sigueitnes etapas.

# Vemos que graficamente son lo mismo, y no tiene sentido que haya misma proporcion de que ganen y pierdan, parece no estar bien los datos recolectados de estas variables
ggplot(data=datosAdult[1:filas,],aes(x=capital_gain_flag,fill=income))+geom_bar()
ggplot(data=datosAdult[1:filas,],aes(x=capital_loss_flag,fill=income))+geom_bar()

# incluso en porcentages se ve mas claro que la mayoria se lo llevan los valores en 0.
sum(datosAdult$capital_gain_flag==0)/length(datosAdult$capital_gain_flag)*100
sum(datosAdult$capital_loss_flag==0)/length(datosAdult$capital_loss_flag)*100



# Para terminar de analizar las razas y paises
#----------------RAZAS-----------------------------------------------------
# Esto confirma que el prejuicio de que los blancos ganan mejores sueldo parece ser verdad, pero se suma aqui que los asiaticos tambien.
ggplot(data=datosAdult[1:filas,],aes(x=race,fill=income))+geom_bar(position="fill")+theme(axis.text.x=element_text(size=8,angle=45))

# Pero que pasa por paises?. Usemos aqui la discretizacion que hicimos antes dodne vimos que la mayorias de las observacioens correspondian a Estados unidos, pero veremos que pasa para el resto del mundo para cada raza.

# Como vemos aqui, claramente tenemos casi todas las observaciones para USA:
ggplot(data=datosAdult[1:filas,],aes(x=country_classif,fill=income))+geom_bar()

# Pero si lo vemos en porcentaje, entre estados unidos y el resto del mundo como conjunto no hay ninguna diferencia que marque que segun de donde seas nativo te garantize un sueldo mayor a 50k, es indistinto, claro esto puede llevar a error, si consideramos a el resto del mundo como un todo, claramente habria que abrir por pais. Dicho esto, con los datos que tenemos excluiria el country de este analisis porque no aporta nada.
ggplot(data=datosAdult[1:filas,],aes(x=country_classif,fill=income))+geom_bar(position="fill")

# Como vemos, sea el pais que sea, la distribucion de ingresos de las razas no es afectada por el pais. 
ggplot(data=datosAdult[1:filas,],aes(x=race,fill=income))+geom_bar(position="fill")+facet_wrap(~country_classif)+theme(axis.text.x=element_text(size=8,angle=45))


```


#### Lectura recomendada:
> **https://arxiv.org/ftp/arxiv/papers/1810/1810.10076.pdf** 
Nivel de analisis al que aspiro llegar.


 ***
# Rúbrica
***
Pregunta Concepto Peso en la nota final

1ª	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1ª	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1b	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1b	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1c	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1c	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

2 Se carga la base de datos, se visualiza su estructura y se explican los hechos básicos. 5%

2 Se estudia si existen atributos vacíos, y si es el caso, se adoptan medidas para tratar estos atributos. 2.5%

2 Se transforma algún atributo para adaptarlo en un estudio posterior. 2.5%

2 Se realiza alguna discretitzación de algún atributo. 2.5%

2 Se crea un indicador nuevo a partido otros atributos 2.5%

2 Se analizan los datos de forma visual y se extraen conclusiones tangibles. Hay que elaborar un discurso coherente y con conclusiones claras. 35%

2 Se trata en profundidad algún otro aspecto respecto a los datos presentado en el módulo 2 15%

2 Se ha buscado información adicional, se ha incluido en el documento de respuesta y las fuentes se han citado correctamente 5%